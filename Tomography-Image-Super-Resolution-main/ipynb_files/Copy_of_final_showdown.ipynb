{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfdf2de0",
   "metadata": {
    "id": "cfdf2de0"
   },
   "source": [
    "**If training on colab, be sure to use a GPU (runtime > Change runtime type > GPU)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3483926b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3483926b",
    "outputId": "22c15027-8b51-4b92-e000-d2d464115d11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.4.3\n",
      "  Downloading tensorflow-2.4.3-cp38-cp38-manylinux2010_x86_64.whl (394.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 394.6 MB 87 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wrapt~=1.12.1 in ./.local/lib/python3.8/site-packages (from tensorflow==2.4.3) (1.12.1)\n",
      "Collecting grpcio~=1.32.0\n",
      "  Downloading grpcio-1.32.0-cp38-cp38-manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting h5py~=2.10.0\n",
      "  Downloading h5py-2.10.0-cp38-cp38-manylinux1_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.5.0,>=2.4.0\n",
      "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: absl-py~=0.10 in ./.local/lib/python3.8/site-packages (from tensorflow==2.4.3) (0.14.1)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in ./.local/lib/python3.8/site-packages (from tensorflow==2.4.3) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in ./.local/lib/python3.8/site-packages (from tensorflow==2.4.3) (3.7.4.3)\n",
      "Requirement already satisfied: wheel~=0.35 in ./.local/lib/python3.8/site-packages (from tensorflow==2.4.3) (0.37.0)\n",
      "Requirement already satisfied: tensorboard~=2.4 in ./.local/lib/python3.8/site-packages (from tensorflow==2.4.3) (2.6.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in ./.local/lib/python3.8/site-packages (from tensorflow==2.4.3) (0.2.0)\n",
      "Collecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in ./.local/lib/python3.8/site-packages (from tensorflow==2.4.3) (1.12)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in ./.local/lib/python3.8/site-packages (from tensorflow==2.4.3) (3.3.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in ./.local/lib/python3.8/site-packages (from tensorflow==2.4.3) (1.19.5)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in ./.local/lib/python3.8/site-packages (from tensorflow==2.4.3) (1.1.2)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in ./.local/lib/python3.8/site-packages (from tensorflow==2.4.3) (3.18.1)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in ./.local/lib/python3.8/site-packages (from tensorflow==2.4.3) (1.6.3)\n",
      "Requirement already satisfied: six~=1.15.0 in ./.local/lib/python3.8/site-packages (from tensorflow==2.4.3) (1.15.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in ./.local/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow==2.4.3) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow==2.4.3) (2.25.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.local/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow==2.4.3) (3.3.4)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in ./.local/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow==2.4.3) (1.35.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in ./anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow==2.4.3) (52.0.0.post20210125)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in ./.local/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow==2.4.3) (2.0.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in ./.local/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow==2.4.3) (1.8.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in ./.local/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow==2.4.3) (0.6.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.3) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.3) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in ./.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.3) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.3) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in ./.local/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.3) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.3) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.3) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in ./anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.3) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.3) (2020.12.5)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Installing collected packages: oauthlib, grpcio, tensorflow-estimator, h5py, gast, tensorflow\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.41.0\n",
      "    Uninstalling grpcio-1.41.0:\n",
      "      Successfully uninstalled grpcio-1.41.0\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.6.0\n",
      "    Uninstalling tensorflow-estimator-2.6.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.6.0\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.1.0\n",
      "    Uninstalling h5py-3.1.0:\n",
      "      Successfully uninstalled h5py-3.1.0\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.4.0\n",
      "    Uninstalling gast-0.4.0:\n",
      "      Successfully uninstalled gast-0.4.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.6.0\n",
      "    Uninstalling tensorflow-2.6.0:\n",
      "      Successfully uninstalled tensorflow-2.6.0\n",
      "Successfully installed gast-0.3.3 grpcio-1.32.0 h5py-2.10.0 oauthlib-3.1.1 tensorflow-2.4.3 tensorflow-estimator-2.4.0\n",
      "Cloning into 'image-super-resolution'...\n",
      "remote: Enumerating objects: 150, done.\u001b[K\n",
      "remote: Counting objects: 100% (150/150), done.\u001b[K\n",
      "remote: Compressing objects: 100% (108/108), done.\u001b[K\n",
      "remote: Total 150 (delta 70), reused 112 (delta 35), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (150/150), 36.74 MiB | 4.72 MiB/s, done.\n",
      "Resolving deltas: 100% (70/70), done.\n"
     ]
    }
   ],
   "source": [
    "# uncomment and run the lines below if running in google colab\n",
    "!pip install tensorflow==2.4.3\n",
    "!git clone https://github.com/jlaihong/image-super-resolution.git\n",
    "!mv image-super-resolution/* ./"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ab2bcb",
   "metadata": {
    "id": "26ab2bcb"
   },
   "source": [
    "# SRResNet and SRGAN Training for Image Super Resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1597e6",
   "metadata": {
    "id": "6e1597e6"
   },
   "source": [
    "An Implementation of SRGAN: https://arxiv.org/pdf/1609.04802.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8fc6ab2",
   "metadata": {
    "id": "f8fc6ab2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-03 02:49:57.180785: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-03 02:49:57.180805: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import PiecewiseConstantDecay\n",
    "from tensorflow.keras.losses import MeanSquaredError, BinaryCrossentropy, MeanAbsoluteError\n",
    "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.metrics import Mean\n",
    "from PIL import Image\n",
    "\n",
    "from datasets.div2k.parameters import Div2kParameters \n",
    "from datasets.div2k.loader import create_training_and_validation_datasets\n",
    "from utils.dataset_mappings import random_crop, random_flip, random_rotate, random_lr_jpeg_noise\n",
    "from utils.metrics import psnr_metric\n",
    "from utils.config import config\n",
    "from utils.callbacks import SaveCustomCheckpoint\n",
    "from models.srresnet import build_srresnet\n",
    "from models.srgan import build_discriminator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1761209",
   "metadata": {
    "id": "f1761209"
   },
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9272c5f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9272c5f4",
    "outputId": "2e7b1da3-7cd8-4fb5-ad35-953ccf93ce06"
   },
   "outputs": [],
   "source": [
    "dataset_key = \"bicubic_x4\"\n",
    "\n",
    "data_path = config.get(\"data_path\", \"\") \n",
    "\n",
    "div2k_folder = os.path.abspath(os.path.join(data_path, \"div2k\"))\n",
    "\n",
    "dataset_parameters = Div2kParameters(dataset_key, save_data_directory=div2k_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "639c8fa0",
   "metadata": {
    "id": "639c8fa0"
   },
   "outputs": [],
   "source": [
    "hr_crop_size = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d48fc71",
   "metadata": {
    "id": "5d48fc71"
   },
   "outputs": [],
   "source": [
    "train_mappings = [\n",
    "    lambda lr, hr: random_crop(lr, hr, hr_crop_size=hr_crop_size, scale=dataset_parameters.scale), \n",
    "    random_flip, \n",
    "    random_rotate, \n",
    "    random_lr_jpeg_noise]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "850ab510",
   "metadata": {
    "id": "850ab510"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find directory:  /home/ubuntu/div2k/DIV2K_train_LR_bicubic/X4\n",
      "/home/ubuntu/div2k\n",
      "Downloading data from http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_LR_bicubic_X4.zip\n",
      "246915072/246914039 [==============================] - 96s 0us/step\n",
      "Begin caching in /home/ubuntu/div2k/cache/DIV2K_train_LR_bicubic/X4/cache.\n",
      "Completed caching in /home/ubuntu/div2k/cache/DIV2K_train_LR_bicubic/X4/cache.\n",
      "Couldn't find directory:  /home/ubuntu/div2k/DIV2K_train_HR\n",
      "/home/ubuntu/div2k\n",
      "Downloading data from http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\n",
      "3530604544/3530603713 [==============================] - 1156s 0us/step\n",
      "Begin caching in /home/ubuntu/div2k/cache/DIV2K_train_HR/cache.\n",
      "Completed caching in /home/ubuntu/div2k/cache/DIV2K_train_HR/cache.\n",
      "Couldn't find directory:  /home/ubuntu/div2k/DIV2K_valid_LR_bicubic/X4\n",
      "/home/ubuntu/div2k\n",
      "Downloading data from http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_valid_LR_bicubic_X4.zip\n",
      "31506432/31505881 [==============================] - 8s 0us/step\n",
      "Begin caching in /home/ubuntu/div2k/cache/DIV2K_valid_LR_bicubic/X4/cache.\n",
      "Completed caching in /home/ubuntu/div2k/cache/DIV2K_valid_LR_bicubic/X4/cache.\n",
      "Couldn't find directory:  /home/ubuntu/div2k/DIV2K_valid_HR\n",
      "/home/ubuntu/div2k\n",
      "Downloading data from http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_valid_HR.zip\n",
      "448995328/448993893 [==============================] - 89s 0us/step\n",
      "Begin caching in /home/ubuntu/div2k/cache/DIV2K_valid_HR/cache.\n",
      "Completed caching in /home/ubuntu/div2k/cache/DIV2K_valid_HR/cache.\n"
     ]
    }
   ],
   "source": [
    "train_dataset, valid_dataset = create_training_and_validation_datasets(dataset_parameters, train_mappings)\n",
    "\n",
    "valid_dataset_subset = valid_dataset.take(10) # only taking 10 examples here to speed up evaluations during training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894b92c5",
   "metadata": {
    "id": "894b92c5"
   },
   "source": [
    "## Train the SRResNet generator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc8149e5",
   "metadata": {
    "id": "dc8149e5"
   },
   "outputs": [],
   "source": [
    "generator = build_srresnet(scale=dataset_parameters.scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7616b43f",
   "metadata": {
    "id": "7616b43f"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir=f'./ckpt/sr_resnet_{dataset_key}'\n",
    "\n",
    "learning_rate=1e-4\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(step=tf.Variable(0),\n",
    "                                 epoch=tf.Variable(0),\n",
    "                                 psnr=tf.Variable(0.0),\n",
    "                                 optimizer=Adam(learning_rate),\n",
    "                                 model=generator)\n",
    "\n",
    "checkpoint_manager = tf.train.CheckpointManager(checkpoint=checkpoint,\n",
    "                                                directory=checkpoint_dir,\n",
    "                                                max_to_keep=3)\n",
    "\n",
    "if checkpoint_manager.latest_checkpoint:\n",
    "    checkpoint.restore(checkpoint_manager.latest_checkpoint)\n",
    "    print(f'Model restored from checkpoint at step {checkpoint.step.numpy()} with validation PSNR {checkpoint.psnr.numpy()}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab25138e",
   "metadata": {
    "id": "ab25138e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing Training from epoch 0. Remaining epochs: 2.\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-03 04:57:55.705927: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 191102976 exceeds 10% of free system memory.\n",
      "2021-12-03 04:57:55.705927: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 191102976 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  1/500 [..............................] - ETA: 52:07 - loss: 5307.0220 - psnr_metric: 11.8027"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-03 04:57:58.680547: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 191102976 exceeds 10% of free system memory.\n",
      "2021-12-03 04:57:58.680547: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 191102976 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  2/500 [..............................] - ETA: 23:16 - loss: 5555.9426 - psnr_metric: 11.5170"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-03 04:58:01.488736: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 191102976 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 1772s 4s/step - loss: 1364.3113 - psnr_metric: 18.5955 - val_loss: 408.0983 - val_psnr_metric: 22.5799\n",
      "Epoch 2/3\n",
      "500/500 [==============================] - 2332s 5s/step - loss: 502.9763 - psnr_metric: 22.7222 - val_loss: 311.9397 - val_psnr_metric: 23.9690\n",
      "Epoch 3/3\n",
      "500/500 [==============================] - 2165s 4s/step - loss: 395.7099 - psnr_metric: 24.0405 - val_loss: 250.3377 - val_psnr_metric: 25.1783\n"
     ]
    }
   ],
   "source": [
    "training_steps = 1000\n",
    "\n",
    "steps_per_epoch = 500\n",
    "\n",
    "training_epochs = training_steps / steps_per_epoch\n",
    "\n",
    "if checkpoint.epoch.numpy() < training_epochs:\n",
    "    remaining_epochs = int(training_epochs - checkpoint.epoch.numpy())\n",
    "    print(f\"Continuing Training from epoch {checkpoint.epoch.numpy()}. Remaining epochs: {remaining_epochs}.\")\n",
    "    save_checkpoint_callback = SaveCustomCheckpoint(checkpoint_manager, steps_per_epoch)\n",
    "    checkpoint.model.compile(optimizer=checkpoint.optimizer, loss=MeanSquaredError(), metrics=[psnr_metric])\n",
    "    checkpoint.model.fit(train_dataset,validation_data=valid_dataset_subset, steps_per_epoch=steps_per_epoch, epochs=3, callbacks=[save_checkpoint_callback])\n",
    "else:\n",
    "    print(\"Training already completed. To continue training, increase the number of training steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7667c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_directory = f\"weights/srresnet_{dataset_key}\"\n",
    "os.makedirs(weights_directory, exist_ok=True)\n",
    "weights_file = f'{weights_directory}/generator.h5'\n",
    "checkpoint.model.save_weights(weights_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3603dc7a",
   "metadata": {
    "id": "3603dc7a"
   },
   "source": [
    "## Train SRGAN using SRResNet as the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9aa5af5c",
   "metadata": {
    "id": "9aa5af5c"
   },
   "outputs": [],
   "source": [
    "generator = build_srresnet(scale=dataset_parameters.scale)\n",
    "generator.load_weights(weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5d2c488",
   "metadata": {
    "id": "c5d2c488"
   },
   "outputs": [],
   "source": [
    "discriminator = build_discriminator(hr_crop_size=hr_crop_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84efb60a",
   "metadata": {
    "id": "84efb60a"
   },
   "outputs": [],
   "source": [
    "layer_5_4 = 20\n",
    "vgg = VGG19(input_shape=(None, None, 3), include_top=False)\n",
    "perceptual_model = Model(vgg.input, vgg.layers[layer_5_4].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9008cee",
   "metadata": {
    "id": "d9008cee"
   },
   "outputs": [],
   "source": [
    "binary_cross_entropy = BinaryCrossentropy()\n",
    "mean_squared_error = MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6cc3a144",
   "metadata": {
    "id": "6cc3a144"
   },
   "outputs": [],
   "source": [
    "learning_rate=PiecewiseConstantDecay(boundaries=[100000], values=[1e-4, 1e-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ba83996",
   "metadata": {
    "id": "8ba83996"
   },
   "outputs": [],
   "source": [
    "generator_optimizer = Adam(learning_rate=learning_rate)\n",
    "discriminator_optimizer = Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8ea9eac",
   "metadata": {
    "id": "b8ea9eac"
   },
   "outputs": [],
   "source": [
    "srgan_checkpoint_dir=f'./ckpt/srgan_{dataset_key}'\n",
    "\n",
    "srgan_checkpoint = tf.train.Checkpoint(step=tf.Variable(0),\n",
    "                                       psnr=tf.Variable(0.0),\n",
    "                                       generator_optimizer=Adam(learning_rate),\n",
    "                                       discriminator_optimizer=Adam(learning_rate),\n",
    "                                       generator=generator,\n",
    "                                       discriminator=discriminator)\n",
    "\n",
    "srgan_checkpoint_manager = tf.train.CheckpointManager(checkpoint=srgan_checkpoint,\n",
    "                                                directory=srgan_checkpoint_dir,\n",
    "                                                max_to_keep=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a113dae5",
   "metadata": {
    "id": "a113dae5"
   },
   "outputs": [],
   "source": [
    "if srgan_checkpoint_manager.latest_checkpoint:\n",
    "    srgan_checkpoint.restore(srgan_checkpoint_manager.latest_checkpoint)\n",
    "    print(f'Model restored from checkpoint at step {srgan_checkpoint.step.numpy()} with validation PSNR {srgan_checkpoint.psnr.numpy()}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6581ee27",
   "metadata": {
    "id": "6581ee27"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(lr, hr):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        lr = tf.cast(lr, tf.float32)\n",
    "        hr = tf.cast(hr, tf.float32)\n",
    "\n",
    "        sr = srgan_checkpoint.generator(lr, training=True)\n",
    "\n",
    "        hr_output = srgan_checkpoint.discriminator(hr, training=True)\n",
    "        sr_output = srgan_checkpoint.discriminator(sr, training=True)\n",
    "\n",
    "        con_loss = calculate_content_loss(hr, sr)\n",
    "        gen_loss = calculate_generator_loss(sr_output)\n",
    "        perc_loss = con_loss + 0.001 * gen_loss\n",
    "        disc_loss = calculate_discriminator_loss(hr_output, sr_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(perc_loss, srgan_checkpoint.generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, srgan_checkpoint.discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, srgan_checkpoint.generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, srgan_checkpoint.discriminator.trainable_variables))\n",
    "\n",
    "    return perc_loss, disc_loss\n",
    "\n",
    "@tf.function\n",
    "def calculate_content_loss(hr, sr):\n",
    "    sr = preprocess_input(sr)\n",
    "    hr = preprocess_input(hr)\n",
    "    sr_features = perceptual_model(sr) / 12.75\n",
    "    hr_features = perceptual_model(hr) / 12.75\n",
    "    return mean_squared_error(hr_features, sr_features)\n",
    "\n",
    "def calculate_generator_loss(sr_out):\n",
    "    return binary_cross_entropy(tf.ones_like(sr_out), sr_out)\n",
    "\n",
    "def calculate_discriminator_loss(hr_out, sr_out):\n",
    "    hr_loss = binary_cross_entropy(tf.ones_like(hr_out), hr_out)\n",
    "    sr_loss = binary_cross_entropy(tf.zeros_like(sr_out), sr_out)\n",
    "    return hr_loss + sr_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50c41e85",
   "metadata": {
    "id": "50c41e85",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/5000, psnr = 17.35757064819336, perceptual loss = 0.1616, discriminator loss = 0.3667 (9433.51s)\n",
      "2000/5000, psnr = 20.70804214477539, perceptual loss = 0.1568, discriminator loss = 0.3132 (9633.08s)\n",
      "3000/5000, psnr = 20.38214111328125, perceptual loss = 0.1540, discriminator loss = 0.2769 (7655.62s)\n",
      "4000/5000, psnr = 21.83553695678711, perceptual loss = 0.1511, discriminator loss = 0.3200 (7364.31s)\n",
      "5000/5000, psnr = 19.311738967895508, perceptual loss = 0.1521, discriminator loss = 0.2438 (7286.52s)\n"
     ]
    }
   ],
   "source": [
    "perceptual_loss_metric = Mean()\n",
    "discriminator_loss_metric = Mean()\n",
    "\n",
    "step = srgan_checkpoint.step.numpy()\n",
    "steps = 5000\n",
    "\n",
    "monitor_folder = f\"monitor_training/srgan_{dataset_key}\"\n",
    "os.makedirs(monitor_folder, exist_ok=True)\n",
    "\n",
    "now = time.perf_counter()\n",
    "\n",
    "for lr, hr in train_dataset.take(steps - step):\n",
    "    srgan_checkpoint.step.assign_add(1)\n",
    "    step = srgan_checkpoint.step.numpy()\n",
    "\n",
    "    perceptual_loss, discriminator_loss = train_step(lr, hr)\n",
    "    perceptual_loss_metric(perceptual_loss)\n",
    "    discriminator_loss_metric(discriminator_loss)\n",
    "\n",
    "    if step % 1000 == 0:\n",
    "        psnr_values = []\n",
    "        \n",
    "        for lr, hr in valid_dataset_subset:\n",
    "            sr = srgan_checkpoint.generator.predict(lr)[0]\n",
    "            sr = tf.clip_by_value(sr, 0, 255)\n",
    "            sr = tf.round(sr)\n",
    "            sr = tf.cast(sr, tf.uint8)\n",
    "            \n",
    "            psnr_value = psnr_metric(hr, sr)[0]\n",
    "            psnr_values.append(psnr_value)\n",
    "            psnr = tf.reduce_mean(psnr_values)\n",
    "            \n",
    "        image = Image.fromarray(sr.numpy())\n",
    "        image.save(f\"{monitor_folder}/{step}.png\" )\n",
    "        \n",
    "        duration = time.perf_counter() - now\n",
    "        \n",
    "        now = time.perf_counter()\n",
    "        \n",
    "        print(f'{step}/{steps}, psnr = {psnr}, perceptual loss = {perceptual_loss_metric.result():.4f}, discriminator loss = {discriminator_loss_metric.result():.4f} ({duration:.2f}s)')\n",
    "        \n",
    "        perceptual_loss_metric.reset_states()\n",
    "        discriminator_loss_metric.reset_states()\n",
    "        \n",
    "        srgan_checkpoint.psnr.assign(psnr)\n",
    "        srgan_checkpoint_manager.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42dbb0cc",
   "metadata": {
    "id": "42dbb0cc"
   },
   "outputs": [],
   "source": [
    "weights_directory = f\"weights/srgan_{dataset_key}\"\n",
    "os.makedirs(weights_directory, exist_ok=True)\n",
    "weights_file = f'{weights_directory}/generator.h5'\n",
    "srgan_checkpoint.generator.save_weights(weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afc9d2e",
   "metadata": {
    "id": "1afc9d2e"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Copy of train_SRRestNet_and_SRGAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
