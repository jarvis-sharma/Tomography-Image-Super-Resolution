{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "step-2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHME2lb8uOwB"
      },
      "source": [
        "#Generative Adversarial Networks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21MBQaEdwf-S"
      },
      "source": [
        "Generative Adversarial Networks, or GANs, are a deep-learning-based generative model.\n",
        "More generally, GANs are a model architecture for training a generative model, and it is most common to use deep learning models in this architecture.\n",
        "\n",
        "<br>\n",
        "\n",
        "A GAN has three primary components: a generator model for generating new data, a discriminator model for classifying whether generated data are real faces, or fake, and the adversarial network that pits them against each other.\n",
        "\n",
        "\n",
        " * Generator. Model that is used to generate new plausible examples from the problem domain.\n",
        " * Discriminator. Model that is used to classify examples as real (from the domain) or fake (generated).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jyya9FxaybR3"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSl-3KtTycEF"
      },
      "source": [
        "Main Idea:\n",
        "\n",
        "* We process the HR(High Resolution) images to get down-sampled LR(Low Resolution) images. Now we have both HR \n",
        "  and LR images for training data set.\n",
        "* We pass LR images through Generator which up-samples and gives SR(Super Resolution) images.\n",
        "* We use a discriminator to distinguish the HR images and back-propagate the GAN loss to train the discriminator\n",
        "  and the generator.\n",
        "* As a result of this, the generator learns to produce more and more realistic images(High Resolution images) as \n",
        "  it trains."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzzOFQcM1mBL"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.layers import Dense\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers.convolutional import UpSampling2D\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers import Input\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.models import Model\n",
        "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
        "from keras.layers import add\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import argparse"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Cbdgz4S23Kt"
      },
      "source": [
        "class Generator(object):\n",
        "\n",
        "    def __init__(self, noise_shape):\n",
        "        \n",
        "        self.noise_shape = noise_shape\n",
        "\n",
        "    def generator(self):\n",
        "        \n",
        "\t    gen_input = Input(shape = self.noise_shape)\n",
        "\t    \n",
        "\t    model = Conv2D(filters = 64, kernel_size = 9, strides = 1, padding = \"same\")(gen_input)\n",
        "\t    model = PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(model)\n",
        "\t    \n",
        "\t    gen_model = model\n",
        "        \n",
        "        # Using 16 Residual Blocks\n",
        "\t    for index in range(16):\n",
        "\t        model = res_block_gen(model, 3, 64, 1)\n",
        "\t    \n",
        "\t    model = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(model)\n",
        "\t    model = BatchNormalization(momentum = 0.5)(model)\n",
        "\t    model = add([gen_model, model])\n",
        "\t    \n",
        "\t    # Using 2 UpSampling Blocks\n",
        "\t    for index in range(2):\n",
        "\t        model = up_sampling_block(model, 3, 256, 1)\n",
        "\t    \n",
        "\t    model = Conv2D(filters = 3, kernel_size = 9, strides = 1, padding = \"same\")(model)\n",
        "\t    model = Activation('tanh')(model)\n",
        "\t   \n",
        "\t    generator_model = Model(inputs = gen_input, outputs = model)\n",
        "        \n",
        "\t    return generator_model"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXVwJ_G84QWI"
      },
      "source": [
        "class Discriminator(object):\n",
        "\n",
        "    def __init__(self, image_shape):\n",
        "        \n",
        "        self.image_shape = image_shape\n",
        "    \n",
        "    def discriminator(self):\n",
        "        \n",
        "        dis_input = Input(shape = self.image_shape)\n",
        "        \n",
        "        model = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(dis_input)\n",
        "        model = LeakyReLU(alpha = 0.2)(model)\n",
        "        \n",
        "        model = discriminator_block(model, 64, 3, 2)\n",
        "        model = discriminator_block(model, 128, 3, 1)\n",
        "        model = discriminator_block(model, 128, 3, 2)\n",
        "        model = discriminator_block(model, 256, 3, 1)\n",
        "        model = discriminator_block(model, 256, 3, 2)\n",
        "        model = discriminator_block(model, 512, 3, 1)\n",
        "        model = discriminator_block(model, 512, 3, 2)\n",
        "        \n",
        "        model = Flatten()(model)\n",
        "        model = Dense(1024)(model)\n",
        "        model = LeakyReLU(alpha = 0.2)(model)\n",
        "       \n",
        "        model = Dense(1)(model)\n",
        "        model = Activation('sigmoid')(model) \n",
        "        \n",
        "        discriminator_model = Model(inputs = dis_input, outputs = model)\n",
        "        \n",
        "        return discriminator_model"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXNCfVs0umYO"
      },
      "source": [
        "plt.switch_backend('agg')\n",
        "\n",
        "# Subpixel Conv will upsample from (h, w, c) to (h/r, w/r, c/r^2)\n",
        "def SubpixelConv2D(input_shape, scale=4):\n",
        "    def subpixel_shape(input_shape):\n",
        "        dims = [input_shape[0],input_shape[1] * scale,input_shape[2] * scale,int(input_shape[3] / (scale ** 2))]\n",
        "        output_shape = tuple(dims)\n",
        "        return output_shape\n",
        "    \n",
        "    def subpixel(x):\n",
        "        return tf.depth_to_space(x, scale)\n",
        "        \n",
        "    return Lambda(subpixel, output_shape=subpixel_shape)\n",
        "    \n",
        "# Takes list of images and provide HR images in form of numpy array\n",
        "def hr_images(images):\n",
        "    images_hr = array(images)\n",
        "    return images_hr\n",
        "\n",
        "# Takes list of images and provide LR images in form of numpy array\n",
        "def lr_images(images_real , downscale):\n",
        "    \n",
        "    images = []\n",
        "    for img in  range(len(images_real)):\n",
        "        images.append(imresize(images_real[img], [images_real[img].shape[0]//downscale,images_real[img].shape[1]//downscale], interp='bicubic', mode=None))\n",
        "    images_lr = array(images)\n",
        "    return images_lr\n",
        "    \n",
        "def normalize(input_data):\n",
        "\n",
        "    return (input_data.astype(np.float32) - 127.5)/127.5 \n",
        "    \n",
        "def denormalize(input_data):\n",
        "    input_data = (input_data + 1) * 127.5\n",
        "    return input_data.astype(np.uint8)\n",
        "   \n",
        " \n",
        "def load_path(path):\n",
        "    directories = []\n",
        "    if os.path.isdir(path):\n",
        "        directories.append(path)\n",
        "    for elem in os.listdir(path):\n",
        "        if os.path.isdir(os.path.join(path,elem)):\n",
        "            directories = directories + load_path(os.path.join(path,elem))\n",
        "            directories.append(os.path.join(path,elem))\n",
        "    return directories\n",
        "    \n",
        "def load_data_from_dirs(dirs, ext):\n",
        "    files = []\n",
        "    file_names = []\n",
        "    count = 0\n",
        "    for d in dirs:\n",
        "        for f in os.listdir(d): \n",
        "            if f.endswith(ext):\n",
        "                image = data.imread(os.path.join(d,f))\n",
        "                if len(image.shape) > 2:\n",
        "                    files.append(image)\n",
        "                    file_names.append(os.path.join(d,f))\n",
        "                count = count + 1\n",
        "    return files     \n",
        "\n",
        "def load_data(directory, ext):\n",
        "\n",
        "    files = load_data_from_dirs(load_path(directory), ext)\n",
        "    return files\n",
        "    \n",
        "def load_training_data(directory, ext, number_of_images = 1000, train_test_ratio = 0.8):\n",
        "\n",
        "    number_of_train_images = int(number_of_images * train_test_ratio)\n",
        "    \n",
        "    files = load_data_from_dirs(load_path(directory), ext)\n",
        "    \n",
        "    if len(files) < number_of_images:\n",
        "        print(\"Number of image files are less then you specified\")\n",
        "        print(\"Please reduce number of images to %d\" % len(files))\n",
        "        sys.exit()\n",
        "        \n",
        "    test_array = array(files)\n",
        "    if len(test_array.shape) < 3:\n",
        "        print(\"Images are of not same shape\")\n",
        "        print(\"Please provide same shape images\")\n",
        "        sys.exit()\n",
        "    \n",
        "    x_train = files[:number_of_train_images]\n",
        "    x_test = files[number_of_train_images:number_of_images]\n",
        "    \n",
        "    x_train_hr = hr_images(x_train)\n",
        "    x_train_hr = normalize(x_train_hr)\n",
        "    \n",
        "    x_train_lr = lr_images(x_train, 4)\n",
        "    x_train_lr = normalize(x_train_lr)\n",
        "    \n",
        "    x_test_hr = hr_images(x_test)\n",
        "    x_test_hr = normalize(x_test_hr)\n",
        "    \n",
        "    x_test_lr = lr_images(x_test, 4)\n",
        "    x_test_lr = normalize(x_test_lr)\n",
        "    \n",
        "    return x_train_lr, x_train_hr, x_test_lr, x_test_hr\n",
        "\n",
        "\n",
        "def load_test_data_for_model(directory, ext, number_of_images = 100):\n",
        "\n",
        "    files = load_data_from_dirs(load_path(directory), ext)\n",
        "    \n",
        "    if len(files) < number_of_images:\n",
        "        print(\"Number of image files are less then you specified\")\n",
        "        print(\"Please reduce number of images to %d\" % len(files))\n",
        "        sys.exit()\n",
        "        \n",
        "    x_test_hr = hr_images(files)\n",
        "    x_test_hr = normalize(x_test_hr)\n",
        "    \n",
        "    x_test_lr = lr_images(files, 4)\n",
        "    x_test_lr = normalize(x_test_lr)\n",
        "    \n",
        "    return x_test_lr, x_test_hr\n",
        "    \n",
        "def load_test_data(directory, ext, number_of_images = 100):\n",
        "\n",
        "    files = load_data_from_dirs(load_path(directory), ext)\n",
        "    \n",
        "    if len(files) < number_of_images:\n",
        "        print(\"Number of image files are less then you specified\")\n",
        "        print(\"Please reduce number of images to %d\" % len(files))\n",
        "        sys.exit()\n",
        "        \n",
        "    x_test_lr = lr_images(files, 4)\n",
        "    x_test_lr = normalize(x_test_lr)\n",
        "    \n",
        "    return x_test_lr\n",
        "    \n",
        "# While training save generated image(in form LR, SR, HR)\n",
        "# Save only one image as sample  \n",
        "def plot_generated_images(output_dir, epoch, generator, x_test_hr, x_test_lr , dim=(1, 3), figsize=(15, 5)):\n",
        "    \n",
        "    examples = x_test_hr.shape[0]\n",
        "    print(examples)\n",
        "    value = randint(0, examples)\n",
        "    image_batch_hr = denormalize(x_test_hr)\n",
        "    image_batch_lr = x_test_lr\n",
        "    gen_img = generator.predict(image_batch_lr)\n",
        "    generated_image = denormalize(gen_img)\n",
        "    image_batch_lr = denormalize(image_batch_lr)\n",
        "    \n",
        "    plt.figure(figsize=figsize)\n",
        "    \n",
        "    plt.subplot(dim[0], dim[1], 1)\n",
        "    plt.imshow(image_batch_lr[value], interpolation='nearest')\n",
        "    plt.axis('off')\n",
        "        \n",
        "    plt.subplot(dim[0], dim[1], 2)\n",
        "    plt.imshow(generated_image[value], interpolation='nearest')\n",
        "    plt.axis('off')\n",
        "    \n",
        "    plt.subplot(dim[0], dim[1], 3)\n",
        "    plt.imshow(image_batch_hr[value], interpolation='nearest')\n",
        "    plt.axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_dir + 'generated_image_%d.png' % epoch)\n",
        "    \n",
        "    #plt.show()\n",
        "    \n",
        "# Plots and save generated images(in form LR, SR, HR) from model to test the model \n",
        "# Save output for all images given for testing  \n",
        "def plot_test_generated_images_for_model(output_dir, generator, x_test_hr, x_test_lr , dim=(1, 3), figsize=(15, 5)):\n",
        "    \n",
        "    examples = x_test_hr.shape[0]\n",
        "    image_batch_hr = denormalize(x_test_hr)\n",
        "    image_batch_lr = x_test_lr\n",
        "    gen_img = generator.predict(image_batch_lr)\n",
        "    generated_image = denormalize(gen_img)\n",
        "    image_batch_lr = denormalize(image_batch_lr)\n",
        "    \n",
        "    for index in range(examples):\n",
        "    \n",
        "        plt.figure(figsize=figsize)\n",
        "    \n",
        "        plt.subplot(dim[0], dim[1], 1)\n",
        "        plt.imshow(image_batch_lr[index], interpolation='nearest')\n",
        "        plt.axis('off')\n",
        "        \n",
        "        plt.subplot(dim[0], dim[1], 2)\n",
        "        plt.imshow(generated_image[index], interpolation='nearest')\n",
        "        plt.axis('off')\n",
        "    \n",
        "        plt.subplot(dim[0], dim[1], 3)\n",
        "        plt.imshow(image_batch_hr[index], interpolation='nearest')\n",
        "        plt.axis('off')\n",
        "    \n",
        "        plt.tight_layout()\n",
        "        plt.savefig(output_dir + 'test_generated_image_%d.png' % index)\n",
        "    \n",
        "        #plt.show()\n",
        "\n",
        "# Takes LR images and save respective HR images\n",
        "def plot_test_generated_images(output_dir, generator, x_test_lr, figsize=(5, 5)):\n",
        "    \n",
        "    examples = x_test_lr.shape[0]\n",
        "    image_batch_lr = denormalize(x_test_lr)\n",
        "    gen_img = generator.predict(image_batch_lr)\n",
        "    generated_image = denormalize(gen_img)\n",
        "    \n",
        "    for index in range(examples):\n",
        "    \n",
        "        #plt.figure(figsize=figsize)\n",
        "    \n",
        "        plt.imshow(generated_image[index], interpolation='nearest')\n",
        "        plt.axis('off')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.savefig(output_dir + 'high_res_result_image_%d.png' % index)\n",
        "    \n",
        "        #plt.show()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogrtBp2I4Uk-"
      },
      "source": [
        "# Residual block\n",
        "def res_block_gen(model, kernal_size, filters, strides):\n",
        "    \n",
        "    gen = model\n",
        "    \n",
        "    model = Conv2D(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n",
        "    model = BatchNormalization(momentum = 0.5)(model)\n",
        "    # Using Parametric ReLU\n",
        "    model = PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(model)\n",
        "    model = Conv2D(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n",
        "    model = BatchNormalization(momentum = 0.5)(model)\n",
        "        \n",
        "    model = add([gen, model])\n",
        "    \n",
        "    return model\n",
        "    \n",
        "    \n",
        "def up_sampling_block(model, kernal_size, filters, strides):\n",
        "    \n",
        "    # In place of Conv2D and UpSampling2D we can also use Conv2DTranspose (Both are used for Deconvolution)\n",
        "    # Even we can have our own function for deconvolution (i.e one made in Utils.py)\n",
        "    #model = Conv2DTranspose(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n",
        "    model = Conv2D(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n",
        "    model = UpSampling2D(size = 2)(model)\n",
        "    model = LeakyReLU(alpha = 0.2)(model)\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "def discriminator_block(model, filters, kernel_size, strides):\n",
        "    \n",
        "    model = Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = \"same\")(model)\n",
        "    model = BatchNormalization(momentum = 0.5)(model)\n",
        "    model = LeakyReLU(alpha = 0.2)(model)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdqnuRdmm0_2"
      },
      "source": [
        "np.random.seed(10)\n",
        "# Better to use downscale factor as 4\n",
        "downscale_factor = 4\n",
        "# Remember to change image shape if you are having different size of images\n",
        "image_shape = (384,384,3)\n",
        "\n",
        "# Combined network\n",
        "def get_gan_network(discriminator, shape, generator, optimizer, vgg_loss):\n",
        "    discriminator.trainable = False\n",
        "    gan_input = Input(shape=shape)\n",
        "    x = generator(gan_input)\n",
        "    gan_output = discriminator(x)\n",
        "    gan = Model(inputs=gan_input, outputs=[x,gan_output])\n",
        "    gan.compile(loss=[vgg_loss, \"binary_crossentropy\"],\n",
        "                loss_weights=[1., 1e-3],\n",
        "                optimizer=optimizer)\n",
        "\n",
        "    return gan\n",
        "\n",
        "# default values for all parameters are given, if want defferent values you can give via commandline\n",
        "# for more info use $python train.py -h\n",
        "def train(epochs, batch_size, input_dir, output_dir, model_save_dir, number_of_images, train_test_ratio):\n",
        "    \n",
        "    x_train_lr, x_train_hr, x_test_lr, x_test_hr = load_training_data(input_dir, '.jpg', number_of_images, train_test_ratio) \n",
        "    loss = VGG_LOSS(image_shape)  \n",
        "    \n",
        "    batch_count = int(x_train_hr.shape[0] / batch_size)\n",
        "    shape = (image_shape[0]//downscale_factor, image_shape[1]//downscale_factor, image_shape[2])\n",
        "    \n",
        "    generator = Generator(shape).generator()\n",
        "    discriminator = Discriminator(image_shape).discriminator()\n",
        "\n",
        "    optimizer = Utils_model.get_optimizer()\n",
        "    generator.compile(loss=loss.vgg_loss, optimizer=optimizer)\n",
        "    discriminator.compile(loss=\"binary_crossentropy\", optimizer=optimizer)\n",
        "    \n",
        "    gan = get_gan_network(discriminator, shape, generator, optimizer, loss.vgg_loss)\n",
        "    \n",
        "    loss_file = open(model_save_dir + 'losses.txt' , 'w+')\n",
        "    loss_file.close()\n",
        "\n",
        "    for e in range(1, epochs+1):\n",
        "        print ('-'*15, 'Epoch %d' % e, '-'*15)\n",
        "        for _ in tqdm(range(batch_count)):\n",
        "            \n",
        "            rand_nums = np.random.randint(0, x_train_hr.shape[0], size=batch_size)\n",
        "            \n",
        "            image_batch_hr = x_train_hr[rand_nums]\n",
        "            image_batch_lr = x_train_lr[rand_nums]\n",
        "            generated_images_sr = generator.predict(image_batch_lr)\n",
        "\n",
        "            real_data_Y = np.ones(batch_size) - np.random.random_sample(batch_size)*0.2\n",
        "            fake_data_Y = np.random.random_sample(batch_size)*0.2\n",
        "            \n",
        "            discriminator.trainable = True\n",
        "            \n",
        "            d_loss_real = discriminator.train_on_batch(image_batch_hr, real_data_Y)\n",
        "            d_loss_fake = discriminator.train_on_batch(generated_images_sr, fake_data_Y)\n",
        "            discriminator_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n",
        "            \n",
        "            rand_nums = np.random.randint(0, x_train_hr.shape[0], size=batch_size)\n",
        "            image_batch_hr = x_train_hr[rand_nums]\n",
        "            image_batch_lr = x_train_lr[rand_nums]\n",
        "\n",
        "            gan_Y = np.ones(batch_size) - np.random.random_sample(batch_size)*0.2\n",
        "            discriminator.trainable = False\n",
        "            gan_loss = gan.train_on_batch(image_batch_lr, [image_batch_hr,gan_Y])\n",
        "            \n",
        "            \n",
        "        print(\"discriminator_loss : %f\" % discriminator_loss)\n",
        "        print(\"gan_loss :\", gan_loss)\n",
        "        gan_loss = str(gan_loss)\n",
        "        \n",
        "        loss_file = open(model_save_dir + 'losses.txt' , 'a')\n",
        "        loss_file.write('epoch%d : gan_loss = %s ; discriminator_loss = %f\\n' %(e, gan_loss, discriminator_loss) )\n",
        "        loss_file.close()\n",
        "\n",
        "        if e == 1 or e % 5 == 0:\n",
        "            Utils.plot_generated_images(output_dir, e, generator, x_test_hr, x_test_lr)\n",
        "        if e % 500 == 0:\n",
        "            generator.save(model_save_dir + 'gen_model%d.h5' % e)\n",
        "            discriminator.save(model_save_dir + 'dis_model%d.h5' % e)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPhkA-5MuqBU"
      },
      "source": [
        "from keras.layers import Lambda\n",
        "import tensorflow as tf\n",
        "from skimage import data, io, filters\n",
        "import numpy as np\n",
        "from numpy import array\n",
        "from numpy.random import randint\n",
        "# from scipy.misc import imresize\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image       \n",
        "# resized_image = numpy.array(Image.fromarray(original_image).resize(newsize))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eF5GWDVCt69G",
        "outputId": "085e1c9f-ffea-4b0a-c091-02d25d6d75d5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive') "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "4SrxoAZPm9B8",
        "outputId": "026fc0d8-63e7-4e17-929e-3ed2848f0773"
      },
      "source": [
        "# parser = argparse.ArgumentParser()\n",
        "\n",
        "# parser.add_argument('-i', '--input_dir', action='store', dest='input_dir', default='./data/' ,\n",
        "#                 help='Path for input images')\n",
        "                \n",
        "# parser.add_argument('-o', '--output_dir', action='store', dest='output_dir', default='./output/' ,\n",
        "#                 help='Path for Output images')\n",
        "\n",
        "# parser.add_argument('-m', '--model_save_dir', action='store', dest='model_save_dir', default='./model/' ,\n",
        "#                 help='Path for model')\n",
        "\n",
        "# parser.add_argument('-b', '--batch_size', action='store', dest='batch_size', default=64,\n",
        "#                 help='Batch Size', type=int)\n",
        "                \n",
        "# parser.add_argument('-e', '--epochs', action='store', dest='epochs', default=1000 ,\n",
        "#                 help='number of iteratios for trainig', type=int)\n",
        "                \n",
        "# parser.add_argument('-n', '--number_of_images', action='store', dest='number_of_images', default=1000 ,\n",
        "#                 help='Number of Images', type= int)\n",
        "                \n",
        "# parser.add_argument('-r', '--train_test_ratio', action='store', dest='train_test_ratio', default=0.8 ,\n",
        "#                 help='Ratio of train and test Images', type=float)\n",
        "\n",
        "# values = parser.parse_args()\n",
        "\n",
        "epochs=100\n",
        "batch_size=10\n",
        "output_dir = \"/content/gdrive/MyDrive/dataset/Non-Glaucoma\"\n",
        "input_dir = \"/content/gdrive/MyDrive/Non-Glaucoma_low\"\n",
        "model_save_dir = \"/content/gdrive/MyDrive/\"\n",
        "number_of_images = 40\n",
        "train_test_ratio = 0.8\n",
        "train(epochs, batch_size, input_dir, output_dir, model_save_dir, number_of_images, train_test_ratio)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of image files are less then you specified\n",
            "Please reduce number of images to 0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MjuYq5fsuN1"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}